#Adapting neural network to handle linear regression
import tensorflow as tf
import numpy as np

class LinearRegression:
    def __init__(self, input_dim):
        self.input_dim = input_dim
        self.W = tf.Variable(tf.random.normal(shape=(input_dim, 1)))
        self.b = tf.Variable(tf.zeros(shape=(1,)))

    def forward_pass(self, X):
        return tf.matmul(X, self.W) + self.b

    def compute_loss(self, y_true, y_pred):
        return tf.reduce_mean(tf.square(y_true - y_pred))

    def update_params(self, lr, grads):
        self.W.assign_sub(lr * grads[0])
        self.b.assign_sub(lr * grads[1])

    def train(self, x_train, y_train, epochs, lr):
        for e in range(epochs):
            with tf.GradientTape() as tape:
                y_pred = self.forward_pass(x_train)
                loss = self.compute_loss(y_train, y_pred)
            grads = tape.gradient(loss, [self.W, self.b])
            self.update_params(lr, grads)
            print(f"Epoch {e+1}, Loss: {loss.numpy():.4f}")

# Example usage
x_train = np.random.rand(100, 1)
y_train = 2 * x_train + 1  # Linear relationship

model = LinearRegression(input_dim=1)
model.train(x_train, y_train, epochs=100, lr=0.01)
